{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6298ae-669b-4042-91fb-8e8eb693926a",
   "metadata": {},
   "source": [
    "# Generating Essays Using a Step-by-Step Approach With LangChain\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/koverholt/gemini-agent-ai-camp/blob/main/2-langchain-essay/langchain-essay.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "This notebook demonstrates how to build an essay-writing pipeline using [LangChain](https://www.langchain.com/), the [Gemini API in Google AI Studio](https://ai.google.dev/gemini-api/docs), and [Tavily](https://tavily.com/) for search.\n",
    "\n",
    "By combining these tools, we create a seamless workflow that plans an essay outline, performs web searches for relevant information, and generates a complete essay draft based on the collected data.\n",
    "\n",
    "This solution showcases the power of chaining LLM models and external tools to tackle complex tasks with minimal human intervention, providing a robust approach to automated content generation.\n",
    "\n",
    "<img src=\"../images/2-langchain-essay.png\" width=\"550px\">\n",
    "\n",
    "## Install depdencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8f5ba7-0b28-4e4f-b714-386109164fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U \\\n",
    "    langchain \\\n",
    "    langchain-google-genai \\\n",
    "    langchain-community \\\n",
    "    tavily-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea14b47c-1781-4870-ac23-224725c4b8dd",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0a528d-1298-411c-a51d-e2bec9832cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from IPython.display import Image, display, Markdown\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c7b495-2b03-40b3-a665-1abf3dab8723",
   "metadata": {},
   "source": [
    "## Configure API keys\n",
    "\n",
    "Get API keys from [Google AI Studio](https://ai.google.dev/gemini-api/docs/api-key) and [Tavily](https://tavily.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80c2042b-6499-4b6b-b0bd-eaaf1aa425fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"YOUR_GOOGLE_AI_STUDIO_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"YOUR_TAVILY_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebf10c-89a0-41bf-b9cf-bcc97f14dab2",
   "metadata": {},
   "source": [
    "## Initialize Gemini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605d0e21-79cd-4d0b-9148-8f8e90eb00c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-002\", temperature=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2088a7-df11-4675-834f-7bc3867be7a1",
   "metadata": {},
   "source": [
    "## Initialize search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14a30816-dcd8-4e12-966d-f0d500b60558",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_tool = TavilySearchResults(max_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905e354-2a93-40b5-a799-2e288418a5ee",
   "metadata": {},
   "source": [
    "## Define prompt templates and Runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f763729d-cef1-4599-893e-b80d8839386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Planning: Create an outline for the essay\n",
    "outline_template = ChatPromptTemplate.from_template(\n",
    "    \"Create a detailed outline for an essay on {topic}\"\n",
    ")\n",
    "\n",
    "\n",
    "# Research: Web search\n",
    "def research_fn(topic):\n",
    "    response = tavily_tool.invoke({\"query\": topic})\n",
    "    return \"\\n\".join([f\"- {result['content']}\" for result in response])\n",
    "\n",
    "\n",
    "# Writing: Write the essay based on outline and research\n",
    "writing_template = ChatPromptTemplate.from_template(\n",
    "    \"Based on the following outline and research, write a 3-paragraph essay on '{topic}':\\n\\nOutline:\\n{outline}\\n\\nResearch:\\n{research}\\n\\nEssay:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac850e45-acfc-495e-b785-d180380e3042",
   "metadata": {},
   "source": [
    "## Define the Runnable Chain using LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc4e385-c143-40cc-bf03-dfc177752ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/v1hjvf8n7yd98mxj_t_h55t80000gn/T/ipykernel_90023/3169385258.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  outline_chain = LLMChain(llm=model, prompt=outline_template)\n"
     ]
    }
   ],
   "source": [
    "# Define individual chains\n",
    "outline_chain = LLMChain(llm=model, prompt=outline_template)\n",
    "writing_chain = LLMChain(llm=model, prompt=writing_template)\n",
    "\n",
    "# Use the pipe operator to combine chains\n",
    "chain = (\n",
    "    outline_chain\n",
    "    | (\n",
    "        lambda result: {\n",
    "            \"topic\": result[\"topic\"],\n",
    "            \"outline\": result[\"text\"],\n",
    "            \"research\": research_fn(result[\"topic\"]),\n",
    "        }\n",
    "    )\n",
    "    | writing_chain\n",
    "    | (lambda result: result[\"text\"])  # Extract the essay text from the final result\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809d58a-3571-4bde-8641-c342015083cb",
   "metadata": {},
   "source": [
    "## Generate an essay on a given topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f5eed4-a557-4ad7-8b2d-973999c62bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The increasing frequency and intensity of hurricanes are stark reminders of the changing climate.  In 2024, the hypothetical Hurricane Helene, a powerful Category 4 storm, ripped through the Atlantic, leaving a trail of destruction in its wake. Though its direct landfall spared major population centers in Florida, Helene's widespread impacts underscored the interconnectedness of ecosystems and the vulnerability of coastal communities to even indirect hurricane effects. From severe flooding in North Carolina to coastal erosion in Florida, Helene's fury served as a potent example of the multifaceted consequences of these extreme weather events.\n",
       "\n",
       "Environmentally, Hurricane Helene wreaked havoc.  Coastal areas in Florida experienced significant beach erosion and dune damage due to the storm surge and powerful waves, jeopardizing crucial ecosystems and coastal infrastructure. Inland, particularly in North Carolina, heavy rainfall led to record flooding, contaminating water supplies, destroying wildlife habitats, and inundating agricultural lands.  The storm's impact on marine life was also substantial, potentially disrupting coral reefs, fish populations, and sea turtle nesting sites.  Further compounding the environmental damage was the massive amount of debris – plastics, building materials, and vegetation – scattered across affected areas, posing a long-term threat to the environment.\n",
       "\n",
       "Economically, the costs of Hurricane Helene were staggering.  The storm inflicted extensive damage to infrastructure, crippling roads, bridges, power grids, and communication networks. Businesses faced significant economic losses from closures, property damage, and supply chain disruptions, particularly those in the tourism and related industries. The financial burden on governments and aid organizations for search and rescue, emergency shelter, medical care, and rebuilding efforts was immense.  Furthermore, the sheer volume of insurance claims for property damage and business interruption placed a significant strain on the insurance industry.  The long-term economic recovery from Helene promised to be a slow and arduous process.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "topic = \"Write an essay about the impacts of Hurricane Helene in 2024\"\n",
    "essay = chain.invoke({\"topic\": topic})\n",
    "display(Markdown(essay))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
